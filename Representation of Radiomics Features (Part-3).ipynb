{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Research Work\\Paper - 4\\BreastLiverNet\\MoNuSAC\\My_Code 19-05-2022 Professor Idea\\Final Code\\Decemeber_22\n",
      "Error: D:\\Research Work\\Paper - 4\\BreastLiverNet\\MoNuSAC\\My_Code 19-05-2022 Professor Idea\\Final Code\\Decemeber_22/Results_ROC - The system cannot find the path specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Loaded\n",
      "\n",
      "Python Version: 3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]\n",
      "Tensor Flow Version: 1.15.0\n",
      "Keras Version: 2.2.4\n",
      "Numpy Version: 1.19.2\n",
      "Pandas Version: 1.1.5\n",
      "OpenCV Version: 4.6.0\n",
      "Scikit-Learn Version: 0.24.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 16929344671444853047,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 15125499085\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 1782287086337258965\n",
       " physical_device_desc: \"device: 0, name: Quadro RTX 5000, pci bus id: 0000:17:00.0, compute capability: 7.5\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "work_directory_R = os.getcwd() + \"/Results_ROC\"\n",
    "work_directory_C = os.getcwd() + \"/Results_CM\"\n",
    "work_directory_P = os.getcwd() + \"/ResultsPredicted\"\n",
    "Results_File = os.getcwd() + \"/Metrics_Result.txt\"\n",
    "\n",
    "import shutil\n",
    "\n",
    "## Try to remove tree; if failed show an error using try...except on screen\n",
    "try:\n",
    "    shutil.rmtree(work_directory_R)\n",
    "    shutil.rmtree(work_directory_C)\n",
    "    shutil.rmtree(work_directory_P)\n",
    "    os.remove(Results_File)\n",
    "except OSError as e:\n",
    "    print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "    \n",
    "import gc as g\n",
    "\n",
    "# %reset\n",
    "from IPython import get_ipython\n",
    "get_ipython().magic('reset -sf') \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "\n",
    "import tensorflow as tf,keras\n",
    "from keras import backend as K, optimizers, regularizers\n",
    "# K.clear_session()\n",
    "\n",
    "import pickle, sys,os,cv2, numpy as np, pandas as pd, scipy, seaborn as sns, json, joblib, sklearn as sk\n",
    "from random import shuffle\n",
    "from keras.models import Sequential, Model, load_model, model_from_json\n",
    "# from keras.layers import Dense, Permute, Dropout, Activation, Flatten, Conv2D, MaxPool2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D, Input, ZeroPadding2D, merge\n",
    "from keras.layers import Dense, Dropout, Permute, Activation, Flatten, Conv2D, MaxPool2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D, Input, ZeroPadding2D, merge\n",
    "from keras.layers import SeparableConv2D, DepthwiseConv2D, BatchNormalization, SpatialDropout2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import utils as np_utils\n",
    "from keras.regularizers import l2, l1_l2\n",
    "from keras.constraints import max_norm\n",
    "\n",
    "from keras.optimizers import Adam,RMSprop,SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator,array_to_img\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "get_ipython().magic('matplotlib inline')\n",
    "%matplotlib inline\n",
    "\n",
    "from keras import layers\n",
    "# from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, RepeatedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, confusion_matrix, roc_curve, auc, recall_score, precision_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# from keras.utils.training_utils import multi_gpu_model\n",
    "# from keras.utils import multi_gpu_model\n",
    "# from keras import layers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "from itertools import cycle\n",
    "from six.moves import cPickle as pickle\n",
    "from scipy import interp\n",
    "from skimage.feature import local_binary_pattern,hog\n",
    "from skimage import data, exposure\n",
    "\n",
    "import itertools\n",
    "from time import time\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from radiomics import featureextractor  # This module is used for interaction with pyradiomics\n",
    "import radiomics\n",
    "# import SimpleITK as sitk\n",
    "import pkgutil\n",
    "import xlsxwriter\n",
    "from PIL import Image\n",
    "from natsort import natsorted\n",
    "\n",
    "print('Libraries Loaded')\n",
    "\n",
    "print()\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "# print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "print(f\"Numpy Version: {np.__version__}\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"OpenCV Version: {cv2.__version__}\")\n",
    "print(f\"Scikit-Learn Version: {sk.__version__}\")\n",
    "\n",
    "tf.__version__\n",
    "tf.test.is_built_with_cuda()\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "# GPU Check 1\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "\n",
    "# from keras import backend as K\n",
    "# print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mode(Organ, work_directory_Pickles, option_Mode):\n",
    "\n",
    "    if option_Mode==1:\n",
    "        Mode = \"Train\"\n",
    "        data_file1 = work_directory_Pickles + '/Classify_C_' + str(Mode) + '_' + str(Organ) + '.pickle'\n",
    "        data_file2 = \"\"\n",
    "        \n",
    "    elif option_Mode==2:\n",
    "        Mode = \"Test\"\n",
    "        data_file1 = work_directory_Pickles + '/Classify_C_' + str(Mode) + '_' + str(Organ) + '.pickle'\n",
    "        data_file2 = \"\"\n",
    "        \n",
    "    elif option_Mode==3:\n",
    "        Mode = \"Train\"\n",
    "        data_file1 = work_directory_Pickles + '/Classify_C_' + str(Mode) + '_' + str(Organ) + '.pickle'\n",
    "\n",
    "        Mode = \"Test\"\n",
    "        data_file2 = work_directory_Pickles + '/Classify_C_' + str(Mode) + '_' + str(Organ) + '.pickle'\n",
    "  \n",
    "    return data_file1, data_file2 \n",
    "\n",
    "\n",
    "def load_pickle(data_file,q):\n",
    "    print('\\nTring to load pickle from %s' % data_file)\n",
    "    with open(data_file, 'rb') as file:\n",
    "        datasets = pickle.load(file)\n",
    "        dataset = datasets['dataset']\n",
    "\n",
    "    X_train = dataset['X_train']\n",
    "    Y_train = dataset['Y_train']\n",
    "    \n",
    "    print('\\nPickle Loaded Successfully!')\n",
    "    \n",
    "    del dataset\n",
    "\n",
    "    if q==1:\n",
    "        print('\\nX_train shape:', X_train.shape)\n",
    "        print('Y_train shape:', Y_train.shape)\n",
    "    \n",
    "    return X_train,Y_train\n",
    "\n",
    "\n",
    "def load_pickle__(data_file,q):\n",
    "    print('\\nTring to load pickle from %s' % data_file)\n",
    "    with open(data_file, 'rb') as file:\n",
    "        datasets = pickle.load(file)\n",
    "        dataset = datasets['dataset']\n",
    "\n",
    "    X_train = dataset['X_train']\n",
    "    Y_train = dataset['Y_train']\n",
    "    Y_train_ = dataset['Y_train_']\n",
    "    \n",
    "    print('\\nPickle Loaded Successfully!')\n",
    "    \n",
    "    del dataset\n",
    "\n",
    "    if q==1:\n",
    "        print('\\nX_train shape:', X_train.shape)\n",
    "        print('Y_train shape:', Y_train.shape)\n",
    "        print('Y_train shape:', Y_train_.shape)\n",
    "    \n",
    "    return X_train,Y_train,Y_train_\n",
    "\n",
    "\n",
    "def save_pickle(x_train,y_train, data_file):\n",
    "    print('\\nTrying to save pickle to %s' % data_file)\n",
    "    \n",
    "    X_train = x_train\n",
    "    Y_train = y_train\n",
    "    del x_train,y_train\n",
    "    \n",
    "    # creating dictionary to store trian and test data\n",
    "    datasets = {'dataset' : {'X_train': X_train,'Y_train': Y_train}}\n",
    "\n",
    "    with open(data_file, 'wb') as file:\n",
    "        pickle.dump(datasets, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        del datasets # to free up memory.\n",
    "        \n",
    "    print('\\nPickle Saved Successfully!')\n",
    "    \n",
    "\n",
    "def save_pickle__(x_train,y_train,y_train_, data_file):\n",
    "    print('\\nTrying to save pickle to %s' % data_file)\n",
    "    \n",
    "    X_train = x_train\n",
    "    Y_train = y_train\n",
    "    Y_train_ = y_train_\n",
    "    del x_train,y_train,y_train_\n",
    "    \n",
    "    # creating dictionary to store trian and test data\n",
    "    datasets = {'dataset' : {'X_train': X_train,'Y_train': Y_train,'Y_train_': Y_train_}}\n",
    "\n",
    "    with open(data_file, 'wb') as file:\n",
    "        pickle.dump(datasets, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        del datasets # to free up memory.\n",
    "        \n",
    "    print('\\nPickle Saved Successfully!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " DataSet-MONUSAC \n",
      "\n",
      "\n",
      "\n",
      "Select Organ\n",
      "\n",
      " 1-Breast \n",
      " 2-Kidney \n",
      " 3-Lung \n",
      " 4-Prostate \n",
      " 5-All \n",
      "4\n",
      "\n",
      "\n",
      "Select Train or Test\n",
      "\n",
      " 1-Train \n",
      " 2-Test \n",
      "1\n",
      "\n",
      "Tring to load pickle from D:\\Research Work\\Paper - 4\\BreastLiverNet\\MoNuSAC\\My_Code 19-05-2022 Professor Idea\\Final Code\\Decemeber_22/January/PICKLESNEW/Classify_C_Train_Prostate.pickle\n",
      "\n",
      "Pickle Loaded Successfully!\n",
      "\n",
      "X_train shape: (975, 107)\n",
      "Y_train shape: (975,)\n",
      "\n",
      "Tring to load pickle from D:\\Research Work\\Paper - 4\\BreastLiverNet\\MoNuSAC\\My_Code 19-05-2022 Professor Idea\\Final Code\\Decemeber_22/January/PICKLESNEW/Classify_C_Train_Prostate_I.pickle\n",
      "\n",
      "Pickle Loaded Successfully!\n",
      "\n",
      "X_train shape: (975, 128, 128, 3)\n",
      "Y_train shape: (975, 128, 128)\n",
      "Y_train shape: (975,)\n"
     ]
    }
   ],
   "source": [
    "work_directory_Pickles = os.path.join(os.getcwd() + \"/January/PICKLESNEW\")\n",
    "\n",
    "print(\"\\n\\n DataSet-MONUSAC \\n\")\n",
    "\n",
    "print('\\n\\nSelect Organ')\n",
    "option_Org = int(input(\"\\n 1-Breast \\n 2-Kidney \\n 3-Lung \\n 4-Prostate \\n 5-All \\n\"))\n",
    "while option_Org  not in (1,2,3,4,5):\n",
    "    option_Org = int(input(\"\\n 1-Breast \\n 2-Kidney \\n 3-Lung \\n 4-Prostate \\n 5-All \\n\"))\n",
    "\n",
    "    \n",
    "print('\\n\\nSelect Train or Test')\n",
    "option_Mode = int(input(\"\\n 1-Train \\n 2-Test \\n\"))\n",
    "while option_Mode  not in (1,2):\n",
    "    option_Mode = int(input(\"\\n 1-Train \\n 2-Test \\n\"))\n",
    "\n",
    "Organ_B = \"Breast\"\n",
    "Organ_K = \"Kidney\"\n",
    "Organ_L = \"Lung\"\n",
    "Organ_P = \"Prostate\"\n",
    "\n",
    "\n",
    "Organ_B_ = \"Breast_I\"\n",
    "Organ_K_ = \"Kidney_I\"\n",
    "Organ_L_ = \"Lung_I\"\n",
    "Organ_P_ = \"Prostate_I\"\n",
    "\n",
    "\n",
    "    \n",
    "if option_Org==1:\n",
    "    data_file, _ = Mode(Organ_B, work_directory_Pickles, option_Mode)\n",
    "    Organ_Output_B, Organ_Label_B = load_pickle(data_file,1)\n",
    "\n",
    "    data_file_, _ = Mode(Organ_B_, work_directory_Pickles, option_Mode)\n",
    "    Organ_Output_B_, Organ_Label_B_, Organ_Label_B__ = load_pickle__(data_file_,1)\n",
    "\n",
    "\n",
    "elif option_Org==2:\n",
    "    data_file, _ = Mode(Organ_K, work_directory_Pickles, option_Mode)\n",
    "    Organ_Output_K, Organ_Label_K = load_pickle(data_file,1)\n",
    "\n",
    "    data_file_, _ = Mode(Organ_K_, work_directory_Pickles, option_Mode)\n",
    "    Organ_Output_K_, Organ_Label_K_, Organ_Label_K__ = load_pickle__(data_file_,1)\n",
    "\n",
    "\n",
    "elif option_Org==3:\n",
    "    data_file, _ = Mode(Organ_L, work_directory_Pickles, option_Mode)\n",
    "    Organ_Output_L, Organ_Label_L = load_pickle(data_file,1)\n",
    "\n",
    "    data_file_, _ = Mode(Organ_L_, work_directory_Pickles, option_Mode)\n",
    "    Organ_Output_L_, Organ_Label_L_, Organ_Label_L__ = load_pickle__(data_file_,1)\n",
    "\n",
    "    \n",
    "elif option_Org==4:\n",
    "    data_file, _ = Mode(Organ_P, work_directory_Pickles, option_Mode)\n",
    "    Organ_Output_P, Organ_Label_P = load_pickle(data_file,1)\n",
    "\n",
    "    data_file_, _ = Mode(Organ_P_, work_directory_Pickles, option_Mode)\n",
    "    Organ_Output_P_, Organ_Label_P_, Organ_Label_P__ = load_pickle__(data_file_,1)\n",
    "\n",
    "    \n",
    "elif option_Org==5:\n",
    "    \n",
    "    data_file, _ = Mode(Organ_B, work_directory_Pickles, option_Mode)\n",
    "    Organ_Output_B, Organ_Label_B = load_pickle(data_file,1)\n",
    "\n",
    "    data_file, _ = Mode(Organ_K, work_directory_Pickles, option_Mode)\n",
    "    Organ_Output_K, Organ_Label_K = load_pickle(data_file,1)\n",
    "\n",
    "    data_file, _ = Mode(Organ_L, work_directory_Pickles, option_Mode)\n",
    "    Organ_Output_L, Organ_Label_L = load_pickle(data_file,1)\n",
    "\n",
    "    data_file, _ = Mode(Organ_P, work_directory_Pickles, option_Mode)\n",
    "    Organ_Output_P, Organ_Label_P = load_pickle(data_file,1)\n",
    "\n",
    "\n",
    "    data_file_, _ = Mode(Organ_B_, work_directory_Pickles, option_Mode)\n",
    "    Organ_Output_B_, Organ_Label_B_, Organ_Label_B__ = load_pickle__(data_file_,1)\n",
    "\n",
    "    data_file_, _ = Mode(Organ_K_, work_directory_Pickles, option_Mode)\n",
    "    Organ_Output_K_, Organ_Label_K_, Organ_Label_K__ = load_pickle__(data_file_,1)\n",
    "\n",
    "    data_file_, _ = Mode(Organ_L_, work_directory_Pickles, option_Mode)\n",
    "    Organ_Output_L_, Organ_Label_L_, Organ_Label_L__ = load_pickle__(data_file_,1)\n",
    "\n",
    "    data_file_, _ = Mode(Organ_P_, work_directory_Pickles, option_Mode)\n",
    "    Organ_Output_P_, Organ_Label_P_, Organ_Label_P__ = load_pickle__(data_file_,1)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Select Class\n",
      "\n",
      " 1-Epithelial \n",
      " 2-Lymphocytes \n",
      " 3-Macrophoges \n",
      " 4-Neutrophils \n",
      "1\n",
      "\n",
      " Labels Portion \n",
      "\n",
      "{0.0: 575, 1.0: 275, 2.0: 70, 3.0: 55}\n",
      "Class 0: 575\n",
      "Class 1: 275\n",
      "Class 2: 70\n",
      "Class 3: 55\n",
      "(575,)\n",
      "\n",
      "\n",
      "X_train shape: (575, 70)\n",
      "Y_train shape: (575,)\n",
      "(575, 128, 128)\n",
      "\n",
      "\n",
      "X_train shape: (575, 128, 128, 3)\n",
      "Y_train shape: (575, 128, 128)\n",
      "Y_train shape: (575, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "def Indices_Type(Organ_Output, Organ_Label, Type_Value, ):\n",
    "\n",
    "    print(\"\\n Labels Portion \\n\")\n",
    "    unique, counts = np.unique(Organ_Label, return_counts=True)\n",
    "    abc= dict(zip(unique, counts))\n",
    "    print(abc)\n",
    "    for i in range(len(abc)):\n",
    "        print('Class %d: %d' % (i, abc[i]))\n",
    "\n",
    "    result_F = np.where(Organ_Label == Type_Value)\n",
    "    \n",
    "    Organ_Output, Organ_Label = Organ_Output[result_F], Organ_Label[result_F]\n",
    "    \n",
    "    return Organ_Output, Organ_Label, result_F\n",
    "\n",
    "\n",
    "print('\\n\\n\\nSelect Class')\n",
    "option_Class = int(input(\"\\n 1-Epithelial \\n 2-Lymphocytes \\n 3-Macrophoges \\n 4-Neutrophils \\n\"))\n",
    "while option_Class  not in (1,2,3,4):\n",
    "    option_Class = int(input(\"\\n 1-Epithelial \\n 2-Lymphocytes \\n 3-Macrophoges \\n 4-Neutrophils \\n\"))\n",
    "\n",
    "if option_Class==1:\n",
    "    Class = \"Epithelial\"\n",
    "    Type_Value = 0\n",
    "    \n",
    "elif option_Class==2:\n",
    "    Class = \"Lymphocytes\"\n",
    "    Type_Value = 1\n",
    "    \n",
    "elif option_Class==3:\n",
    "    Class = \"Macrophoges\"\n",
    "    Type_Value = 2\n",
    "    \n",
    "elif option_Class==4:\n",
    "    Class = \"Neutrophils\"\n",
    "    Type_Value = 3\n",
    "    \n",
    "    \n",
    "if option_Org==1:\n",
    "    Nuceli_Output_Type_B, Nuceli_Label_Type_B, result_Indices_B = Indices_Type(Organ_Output_B, Organ_Label_B, Type_Value)\n",
    "    print(Nuceli_Label_Type_B.shape)\n",
    "    \n",
    "    Nuceli_Output_Type = Nuceli_Output_Type_B\n",
    "    Nuceli_Label_Type = Nuceli_Label_Type_B\n",
    "\n",
    "    samples_Select = 70\n",
    "    Nuceli_Output_Type = Nuceli_Output_Type[:, 32:102]\n",
    "\n",
    "    print('\\n\\nX_train shape:', Nuceli_Output_Type.shape)\n",
    "    print('Y_train shape:', Nuceli_Label_Type.shape) \n",
    "\n",
    "    Nuceli_Output_Type_B_I, Nuceli_Label_Type_B_I, Nuceli_Label_Type_B_I_ = Organ_Output_B_[result_Indices_B], Organ_Label_B_[result_Indices_B], Organ_Label_B__[result_Indices_B]\n",
    "    print(Nuceli_Label_Type_B_I.shape)\n",
    "\n",
    "    Nuceli_Output_Type_I = Nuceli_Output_Type_B_I\n",
    "    Nuceli_Label_Type_I = Nuceli_Label_Type_B_I\n",
    "    Nuceli_Label_Type_I_ = Nuceli_Label_Type_B_I_\n",
    "    \n",
    "    \n",
    "elif option_Org==2:\n",
    "    Nuceli_Output_Type_K, Nuceli_Label_Type_K, result_Indices_K = Indices_Type(Organ_Output_K, Organ_Label_K, Type_Value)\n",
    "    print(Nuceli_Label_Type_K.shape)\n",
    "\n",
    "    Nuceli_Output_Type = Nuceli_Output_Type_K   \n",
    "    Nuceli_Label_Type = Nuceli_Label_Type_K\n",
    "    \n",
    "    samples_Select = 70\n",
    "    Nuceli_Output_Type = Nuceli_Output_Type[:, 32:102]\n",
    "\n",
    "    print('\\n\\nX_train shape:', Nuceli_Output_Type.shape)\n",
    "    print('Y_train shape:', Nuceli_Label_Type.shape) \n",
    "\n",
    "    Nuceli_Output_Type_K_I, Nuceli_Label_Type_K_I, Nuceli_Label_Type_K_I_ = Organ_Output_K_[result_Indices_K], Organ_Label_K_[result_Indices_K], Organ_Label_K__[result_Indices_K]\n",
    "    print(Nuceli_Label_Type_K_I.shape)\n",
    "    \n",
    "    Nuceli_Output_Type_I = Nuceli_Output_Type_K_I\n",
    "    Nuceli_Label_Type_I = Nuceli_Label_Type_K_I\n",
    "    Nuceli_Label_Type_I_ = Nuceli_Label_Type_K_I_\n",
    "    \n",
    "\n",
    "elif option_Org==3:\n",
    "    Nuceli_Output_Type_L, Nuceli_Label_Type_L, result_Indices_L = Indices_Type(Organ_Output_L, Organ_Label_L, Type_Value)\n",
    "    print(Nuceli_Label_Type_L.shape)\n",
    "\n",
    "    Nuceli_Output_Type = Nuceli_Output_Type_L\n",
    "    Nuceli_Label_Type = Nuceli_Label_Type_L\n",
    "\n",
    "    samples_Select = 70\n",
    "    Nuceli_Output_Type = Nuceli_Output_Type[:, 32:102]\n",
    "\n",
    "    print('\\n\\nX_train shape:', Nuceli_Output_Type.shape)\n",
    "    print('Y_train shape:', Nuceli_Label_Type.shape) \n",
    "\n",
    "    Nuceli_Output_Type_L_I, Nuceli_Label_Type_L_I, Nuceli_Label_Type_L_I_ = Organ_Output_L_[result_Indices_L], Organ_Label_L_[result_Indices_L], Organ_Label_L__[result_Indices_L]\n",
    "    print(Nuceli_Label_Type_L_I.shape)\n",
    "\n",
    "    Nuceli_Output_Type_I = Nuceli_Output_Type_L_I\n",
    "    Nuceli_Label_Type_I = Nuceli_Label_Type_L_I\n",
    "    Nuceli_Label_Type_I_ = Nuceli_Label_Type_L_I_\n",
    "    \n",
    "\n",
    "elif option_Org==4:\n",
    "    Nuceli_Output_Type_P, Nuceli_Label_Type_P, result_Indices_P = Indices_Type(Organ_Output_P, Organ_Label_P, Type_Value)\n",
    "    print(Nuceli_Label_Type_P.shape)\n",
    "\n",
    "    Nuceli_Output_Type = Nuceli_Output_Type_P\n",
    "    Nuceli_Label_Type = Nuceli_Label_Type_P\n",
    "\n",
    "    samples_Select = 70\n",
    "    Nuceli_Output_Type = Nuceli_Output_Type[:, 32:102]\n",
    "\n",
    "    print('\\n\\nX_train shape:', Nuceli_Output_Type.shape)\n",
    "    print('Y_train shape:', Nuceli_Label_Type.shape) \n",
    "\n",
    "    Nuceli_Output_Type_P_I, Nuceli_Label_Type_P_I, Nuceli_Label_Type_P_I_ = Organ_Output_P_[result_Indices_P], Organ_Label_P_[result_Indices_P], Organ_Label_P__[result_Indices_P]\n",
    "    print(Nuceli_Label_Type_P_I.shape)\n",
    "\n",
    "    Nuceli_Output_Type_I = Nuceli_Output_Type_P_I\n",
    "    Nuceli_Label_Type_I = Nuceli_Label_Type_P_I\n",
    "    Nuceli_Label_Type_I_ = Nuceli_Label_Type_P_I_\n",
    "    \n",
    "    \n",
    "elif option_Org==5:\n",
    "    Nuceli_Output_Type_B, Nuceli_Label_Type_B, result_Indices_B = Indices_Type(Organ_Output_B, Organ_Label_B, Type_Value)\n",
    "    print(Nuceli_Label_Type_B.shape)\n",
    "\n",
    "    Nuceli_Output_Type_K, Nuceli_Label_Type_K, result_Indices_K = Indices_Type(Organ_Output_K, Organ_Label_K, Type_Value)\n",
    "    print(Nuceli_Label_Type_K.shape)\n",
    "\n",
    "    Nuceli_Output_Type_L, Nuceli_Label_Type_L, result_Indices_L = Indices_Type(Organ_Output_L, Organ_Label_L, Type_Value)\n",
    "    print(Nuceli_Label_Type_L.shape)\n",
    "\n",
    "    Nuceli_Output_Type_P, Nuceli_Label_Type_P, result_Indices_P = Indices_Type(Organ_Output_P, Organ_Label_P, Type_Value)\n",
    "    print(Nuceli_Label_Type_P.shape)\n",
    "\n",
    "    Nuceli_Output_Type = np.concatenate((Nuceli_Output_Type_B, Nuceli_Output_Type_K, Nuceli_Output_Type_L, Nuceli_Output_Type_P), axis=0)\n",
    "    Nuceli_Label_Type = np.concatenate((Nuceli_Label_Type_B, Nuceli_Label_Type_K, Nuceli_Label_Type_L, Nuceli_Label_Type_P), axis=0)\n",
    "    \n",
    "    samples_Select = 70\n",
    "    Nuceli_Output_Type = Nuceli_Output_Type[:, 32:102]\n",
    "\n",
    "    print('\\n\\nX_train shape:', Nuceli_Output_Type.shape)\n",
    "    print('Y_train shape:', Nuceli_Label_Type.shape) \n",
    "\n",
    "\n",
    "\n",
    "    Nuceli_Output_Type_B_I, Nuceli_Label_Type_B_I, Nuceli_Label_Type_B_I_ = Organ_Output_B_[result_Indices_B], Organ_Label_B_[result_Indices_B], Organ_Label_B__[result_Indices_B]\n",
    "    print(Nuceli_Label_Type_B_I.shape)\n",
    "\n",
    "    Nuceli_Output_Type_K_I, Nuceli_Label_Type_K_I, Nuceli_Label_Type_K_I_ = Organ_Output_K_[result_Indices_K], Organ_Label_K_[result_Indices_K], Organ_Label_K__[result_Indices_K]\n",
    "    print(Nuceli_Label_Type_K_I.shape)\n",
    "\n",
    "    Nuceli_Output_Type_L_I, Nuceli_Label_Type_L_I, Nuceli_Label_Type_L_I_ = Organ_Output_L_[result_Indices_L], Organ_Label_L_[result_Indices_L], Organ_Label_L__[result_Indices_L]\n",
    "    print(Nuceli_Label_Type_L_I.shape)\n",
    "\n",
    "    Nuceli_Output_Type_P_I, Nuceli_Label_Type_P_I, Nuceli_Label_Type_P_I_ = Organ_Output_P_[result_Indices_P], Organ_Label_P_[result_Indices_P], Organ_Label_P__[result_Indices_P]\n",
    "    print(Nuceli_Label_Type_P_I.shape)\n",
    "\n",
    "    Nuceli_Output_Type_I = np.concatenate((Nuceli_Output_Type_B_I, Nuceli_Output_Type_K_I, Nuceli_Output_Type_L_I, Nuceli_Output_Type_P_I), axis=0)\n",
    "    Nuceli_Label_Type_I = np.concatenate((Nuceli_Label_Type_B_I, Nuceli_Label_Type_K_I, Nuceli_Label_Type_L_I, Nuceli_Label_Type_P_I), axis=0)\n",
    "    Nuceli_Label_Type_I_ = np.concatenate((Nuceli_Label_Type_B_I_, Nuceli_Label_Type_K_I_, Nuceli_Label_Type_L_I_, Nuceli_Label_Type_P_I_), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "print('\\n\\nX_train shape:', Nuceli_Output_Type_I.shape)\n",
    "print('Y_train shape:', Nuceli_Label_Type_I.shape) \n",
    "print('Y_train shape:', Nuceli_Label_Type_I.shape) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "X_train shape: (540, 70)\n",
      "Y_train shape: (540,)\n",
      "Y_train shape: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\nX_train shape:', Nuceli_Output_Type.shape)\n",
    "print('Y_train shape:', Nuceli_Label_Type.shape) \n",
    "print('Y_train shape:', Nuceli_Label_Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "X_train shape: (540, 70)\n",
      "Y_train shape: (540,)\n",
      "\n",
      " Labels Portion \n",
      "\n",
      "{0.0: 540}\n",
      "\n",
      "Trying to save pickle to January/PICKLESNEW/Classify_D_Breast_E-GLCM GLDM GLRLM GLSZM_70.pickle\n",
      "\n",
      "Pickle Saved Successfully!\n",
      "\n",
      " Labels Portion \n",
      "\n",
      "{0.0: 540}\n",
      "\n",
      "Trying to save pickle to January/PICKLESNEW/Classify_D_Breast_I_E-GLCM GLDM GLRLM GLSZM_70.pickle\n",
      "\n",
      "Pickle Saved Successfully!\n"
     ]
    }
   ],
   "source": [
    "samples_Select = 70\n",
    "\n",
    "# 1-Epithelial\n",
    "if option_Class==1:\n",
    "    Name_T = \"E-GLCM GLDM GLRLM GLSZM\"\n",
    "    \n",
    "# 2-Lymphocytes \n",
    "elif option_Class==2:\n",
    "    Name_T = \"L-GLCM GLDM GLRLM GLSZM\"\n",
    "    \n",
    "# 3-Macrophoges \n",
    "elif option_Class==3:\n",
    "    Name_T = \"M-GLCM GLDM GLRLM GLSZM\"\n",
    "\n",
    "# 4-Neutrophils\n",
    "elif option_Class==4:\n",
    "    Name_T = \"N-GLCM GLDM GLRLM GLSZM\"\n",
    "    \n",
    "X_train = Nuceli_Output_Type\n",
    "Y_train = Nuceli_Label_Type\n",
    "\n",
    "\n",
    "print('\\n\\nX_train shape:', Nuceli_Output_Type.shape)\n",
    "print('Y_train shape:', Nuceli_Label_Type.shape) \n",
    "\n",
    "print(\"\\n Labels Portion \\n\")\n",
    "unique, counts = np.unique(Nuceli_Label_Type, return_counts=True)\n",
    "abc= dict(zip(unique, counts))\n",
    "print(abc)\n",
    "\n",
    "\n",
    "\n",
    "if option_Org==1:\n",
    "    data_file = 'January/PICKLESNEW/Classify_D_Breast_' + str(Name_T) + '_' + str(samples_Select) + '.pickle'   \n",
    "    data_file_ = 'January/PICKLESNEW/Classify_D_Breast_I_' + str(Name_T) + '_' + str(samples_Select) + '.pickle'   \n",
    "\n",
    "elif option_Org==2:\n",
    "    data_file = 'January/PICKLESNEW/Classify_D_Kidney_' + str(Name_T) + '_' + str(samples_Select) + '.pickle'   \n",
    "    data_file_ = 'January/PICKLESNEW/Classify_D_Kidney_I_' + str(Name_T) + '_' + str(samples_Select) + '.pickle'   \n",
    "\n",
    "elif option_Org==3:\n",
    "    data_file = 'January/PICKLESNEW/Classify_D_Lung_' + str(Name_T) + '_' + str(samples_Select) + '.pickle'   \n",
    "    data_file_ = 'January/PICKLESNEW/Classify_D_Lung_I_' + str(Name_T) + '_' + str(samples_Select) + '.pickle'   \n",
    "\n",
    "elif option_Org==4:\n",
    "    data_file = 'January/PICKLESNEW/Classify_D_Prostate_' + str(Name_T) + '_' + str(samples_Select) + '.pickle'   \n",
    "    data_file_ = 'January/PICKLESNEW/Classify_D_Prostate_I_' + str(Name_T) + '_' + str(samples_Select) + '.pickle'   \n",
    "\n",
    "elif option_Org==5:\n",
    "    data_file = 'January/PICKLESNEW/Classify_D_All_' + str(Name_T) + '_' + str(samples_Select) + '.pickle'   \n",
    "    data_file_ = 'January/PICKLESNEW/Classify_D_All_I_' + str(Name_T) + '_' + str(samples_Select) + '.pickle'   \n",
    "    \n",
    "    \n",
    "save_pickle(Nuceli_Output_Type, Nuceli_Label_Type, data_file)\n",
    "\n",
    "\n",
    "print(\"\\n Labels Portion \\n\")\n",
    "unique, counts = np.unique(Nuceli_Label_Type_I_, return_counts=True)\n",
    "abc= dict(zip(unique, counts))\n",
    "print(abc)\n",
    "\n",
    "\n",
    "save_pickle__(Nuceli_Output_Type_I, Nuceli_Label_Type_I, Nuceli_Label_Type_I_, data_file_)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
