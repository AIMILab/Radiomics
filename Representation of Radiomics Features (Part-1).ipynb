{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyradiomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # needed navigate the system to get the input data\n",
    "from radiomics import featureextractor  # This module is used for interaction with pyradiomics\n",
    "import radiomics\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import cv2, pkgutil\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "from csv import writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_cmatrices\n",
      "_cshape\n",
      "_version\n",
      "base\n",
      "featureextractor\n",
      "features\n",
      "firstorder\n",
      "generalinfo\n",
      "glcm\n",
      "gldm\n",
      "glrlm\n",
      "glszm\n",
      "imageoperations\n",
      "ngtdm\n",
      "scripts\n",
      "shape\n",
      "shape2D\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # print(os.listdir(os.path.dirname(radiomics.__file__)))\n",
    "\n",
    "# for _, mod, _ in pkgutil.iter_modules([os.path.dirname(radiomics.__file__)]):\n",
    "#     print(mod)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindBoundingBox( contour ):\n",
    "    x,y,w,h = cv2.boundingRect( contour )\n",
    "    return x,y,w,h\n",
    "\n",
    "\n",
    "\n",
    "def append_list_as_row(file_name, list_of_elem):\n",
    "    # Open file in append mode\n",
    "    with open(file_name, 'a+', newline='') as write_obj:\n",
    "        # Create a writer object from csv module\n",
    "        csv_writer = writer(write_obj)\n",
    "        # Add contents of list as last row in the csv file\n",
    "        csv_writer.writerow(list_of_elem)\n",
    "        \n",
    "\n",
    "        \n",
    "def color_define_contour(label):\n",
    "    \n",
    "    if label==0:\n",
    "        color = (255, 0, 0)\n",
    "    \n",
    "    elif label==1:\n",
    "        color = (255, 255, 0)\n",
    "    \n",
    "    elif label==2:\n",
    "        color = (0, 0, 255)\n",
    "    \n",
    "    elif label==3:\n",
    "        color = (0, 100, 0)        \n",
    "        \n",
    "    return color\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(data_file,q):\n",
    "    # Reading dictionary to load train and test data\n",
    "    print('\\nTring to load pickle from %s' % data_file)\n",
    "    with open(data_file, 'rb') as file:\n",
    "        datasets = pickle.load(file)\n",
    "        dataset = datasets['dataset']\n",
    "\n",
    "    print('\\nPickle Loaded Successfully!')\n",
    "\n",
    "    X_train = dataset['X_train']\n",
    "    Y_train = dataset['Y_train']\n",
    "    del dataset\n",
    "\n",
    "    if q==1:\n",
    "        print('\\nX_train shape:', X_train.shape)\n",
    "        print('Y_train shape:', Y_train.shape)\n",
    "\n",
    "    return X_train,Y_train\n",
    "\n",
    "\n",
    "\n",
    "def save_pickle(x_train,y_train, data_file):\n",
    "    # Reading dictionary to save train and test data\n",
    "    print('\\nTrying to save pickle to %s' % data_file)\n",
    "\n",
    "    X_train = x_train\n",
    "    Y_train = y_train\n",
    "    del x_train,y_train\n",
    "\n",
    "    # creating dictionary to store train and test data\n",
    "    datasets = {\n",
    "        'dataset': {'X_train': X_train,'Y_train': Y_train}}\n",
    "\n",
    "    with open(data_file, 'wb') as file:\n",
    "        pickle.dump(datasets, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        del datasets # to free up memory.\n",
    "\n",
    "    print('\\nPickle Saved Successfully!')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select Organ\n",
      "\n",
      " 1-Breast \n",
      " 2-Kidney \n",
      " 3-Lung \n",
      " 4-Prostate \n",
      "4\n",
      "\n",
      "Total Images:  46\n",
      "Total Masks:  46\n",
      "46\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "##################### Our Technqiue #####################\n",
    "patch_size = (128, 128)\n",
    "step = 200\n",
    "\n",
    "print('\\nSelect Organ')\n",
    "option_Organ = int(input(\"\\n 1-Breast \\n 2-Kidney \\n 3-Lung \\n 4-Prostate \\n\"))\n",
    "while option_Organ  not in (1,2,3,4,5):\n",
    "    option_Organ = int(input(\"\\n 1-Breast \\n 2-Kidney \\n 3-Lung \\n 4-Prostate \\n\"))\n",
    "\n",
    "if option_Organ==1:\n",
    "    Organ = \"Breast\"\n",
    "elif option_Organ==2:\n",
    "    Organ = \"Kidney\"\n",
    "elif option_Organ==3:\n",
    "    Organ = \"Lung\"\n",
    "elif option_Organ==4:\n",
    "    Organ = \"Prostate\"\n",
    "    \n",
    "    \n",
    "\n",
    "data_folder_R = \"D://Taimoor_Datasets/Thesis/Nuclei/MoNuSAC/\"\n",
    "\n",
    "Mode = \"Train\"\n",
    "path_ = \"D://Taimoor_Datasets/Thesis/Nuclei/MoNuSAC/Select_January_23/Training_Data_Classwise_\" + str(patch_size[0]) + \"_\" + str(step) + \"/Data_Patches/\" + str(Organ)\n",
    "\n",
    "# # Mode = \"Test\"\n",
    "# path_ = \"D://Taimoor_Datasets/Thesis/Nuclei/MoNuSAC/Select_January_23/Testing_Data_Classwise_\" + str(patch_size[0]) + \"_\" + str(step) + \"/Data_Patches/\" + str(Organ) \n",
    "\n",
    "data_folder1 = \"/Images/\"\n",
    "path1  = path_ + data_folder1\n",
    "folder1 = sorted(os.listdir(path1))\n",
    "print('\\nTotal Images: ', len(folder1))\n",
    "\n",
    "data_folder2 = \"/Masks/\"\n",
    "path2  = path_ + data_folder2\n",
    "folder2 = sorted(os.listdir(path2))\n",
    "print('Total Masks: ', len(folder2))\n",
    "\n",
    "folder_diff = [file for file in folder1 if file.endswith(\".png\")]\n",
    "folder_label = [file for file in folder2 if file.endswith(\".png\")]\n",
    "\n",
    "print(len(folder_diff))\n",
    "print(len(folder_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D://Taimoor_Datasets/Thesis/Nuclei/MoNuSAC/Select_January_23/Training_Data_Classwise_128_200/Data_Patches/Prostate/Images/\n",
      "D://Taimoor_Datasets/Thesis/Nuclei/MoNuSAC/Select_January_23/Training_Data_Classwise_128_200/Data_Patches/Prostate/Masks/\n"
     ]
    }
   ],
   "source": [
    "print(path1)\n",
    "print(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Image-0' 'Image-1' 'Image-2' 'Image-3' 'Image-4' 'Image-5' 'Image-6'\n",
      " 'Image-7']\n",
      "\n",
      "Length:  8\n",
      "\n",
      "\n",
      "Image-0\n",
      "Image-1\n",
      "Image-2\n",
      "Image-3\n",
      "Image-4\n",
      "Image-5\n",
      "Image-6\n",
      "Image-7\n"
     ]
    }
   ],
   "source": [
    "from natsort import natsorted\n",
    "\n",
    "No_Count = []\n",
    "\n",
    "for seq in np.asarray(natsorted(folder_diff)): \n",
    "    Images_No = seq.split('_')[0]\n",
    "    No_Count.append(Images_No)\n",
    "\n",
    "temp = np.unique(No_Count)\n",
    "print(temp)\n",
    "\n",
    "print(\"\\nLength: \",len(temp))\n",
    "\n",
    "print(\"\\n\")\n",
    "for seq in natsorted(temp): \n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Count_L = 0\n",
    "\n",
    "Images = []\n",
    "Labels = []\n",
    "\n",
    "for seq in np.asarray(natsorted(folder_diff)): \n",
    "\n",
    "    imagePath = os.path.join(path1, str(natsorted(folder_diff)[Count_L]))    \n",
    "    img=cv2.imread(os.path.join(imagePath))\n",
    "    Images.append(img)\n",
    "    \n",
    "    for temp_ in natsorted(temp): \n",
    "\n",
    "        if temp_ == seq.split('_')[0]:\n",
    "            \n",
    "            Image_No = int(seq.split('_')[0].split('-')[1])\n",
    "            Mask_No = int(seq.split('_')[1].split('-')[1])\n",
    "            C = seq.split('_')[2]\n",
    "\n",
    "            if C==\"Type-E\":\n",
    "                Labels_No = 0\n",
    "                Labels.append(Labels_No)\n",
    "\n",
    "            elif C==\"Type-L\":\n",
    "                Labels_No = 1\n",
    "                Labels.append(Labels_No)\n",
    "\n",
    "            elif C==\"Type-M\":\n",
    "                Labels_No = 2\n",
    "                Labels.append(Labels_No)\n",
    "\n",
    "            elif C==\"Type-N\":\n",
    "                Labels_No = 3\n",
    "                Labels.append(Labels_No)\n",
    "\n",
    "    Count_L = Count_L + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 128, 128, 3)\n",
      "(46,)\n",
      "[0 1 3 0 0 0 1 1 1 2 2 2 0 0 0 1 1 1 2 2 2 0 1 3 0 0 0 0 1 2 0 1 1 3 1 1 2\n",
      " 2 2 3 1 1 2 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "\n",
    "Images_ = np.asarray(Images) \n",
    "print(Images_.shape)\n",
    "\n",
    "Labels_ = np.asarray(Labels) \n",
    "print(Labels_.shape)\n",
    "print(Labels_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January/PICKLESNEW/Classify_Train_Texture_New_Prostate.pickle\n"
     ]
    }
   ],
   "source": [
    "data_file = 'January/PICKLESNEW/Classify_B_' + str(Mode) + '_' + str(Organ) + '.pickle'   \n",
    "print(data_file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D://Taimoor_Datasets/Thesis/Nuclei/MoNuSAC/Augment_January_23\\Result_Train_Labels/Prostate.csv\n",
      "\n",
      "\t\t\t\t===== Processing Image =====\n",
      "\n",
      "Image #:  0\n",
      "\n",
      "Image #:  1\n",
      "# of Contours:  1\n",
      "# of Hierarchy:  1\n",
      "[1]\n",
      "\n",
      "Image #:  2\n",
      "# of Contours:  34\n",
      "# of Hierarchy:  1\n",
      "[1, 34]\n",
      "\n",
      "Image #:  3\n",
      "# of Contours:  49\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49]\n",
      "\n",
      "Image #:  4\n",
      "# of Contours:  93\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93]\n",
      "\n",
      "Image #:  5\n",
      "# of Contours:  64\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64]\n",
      "\n",
      "Image #:  6\n",
      "# of Contours:  67\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67]\n",
      "\n",
      "Image #:  7\n",
      "# of Contours:  54\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54]\n",
      "\n",
      "Image #:  8\n",
      "# of Contours:  8\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8]\n",
      "\n",
      "Image #:  9\n",
      "# of Contours:  1\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1]\n",
      "\n",
      "Image #:  10\n",
      "# of Contours:  21\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21]\n",
      "\n",
      "Image #:  11\n",
      "# of Contours:  1\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1]\n",
      "\n",
      "Image #:  12\n",
      "# of Contours:  49\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49]\n",
      "\n",
      "Image #:  13\n",
      "# of Contours:  93\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93]\n",
      "\n",
      "Image #:  14\n",
      "# of Contours:  64\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64]\n",
      "\n",
      "Image #:  15\n",
      "# of Contours:  67\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67]\n",
      "\n",
      "Image #:  16\n",
      "# of Contours:  54\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54]\n",
      "\n",
      "Image #:  17\n",
      "# of Contours:  8\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8]\n",
      "\n",
      "Image #:  18\n",
      "# of Contours:  1\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1]\n",
      "\n",
      "Image #:  19\n",
      "# of Contours:  21\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21]\n",
      "\n",
      "Image #:  20\n",
      "# of Contours:  1\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1]\n",
      "\n",
      "Image #:  21\n",
      "# of Contours:  1\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1]\n",
      "\n",
      "Image #:  22\n",
      "# of Contours:  2\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2]\n",
      "\n",
      "Image #:  23\n",
      "# of Contours:  4\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4]\n",
      "\n",
      "Image #:  24\n",
      "# of Contours:  36\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36]\n",
      "\n",
      "Image #:  25\n",
      "# of Contours:  49\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49]\n",
      "\n",
      "Image #:  26\n",
      "# of Contours:  46\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46]\n",
      "\n",
      "Image #:  27\n",
      "# of Contours:  28\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28]\n",
      "\n",
      "Image #:  28\n",
      "# of Contours:  4\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4]\n",
      "\n",
      "Image #:  29\n",
      "# of Contours:  2\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2]\n",
      "\n",
      "Image #:  30\n",
      "# of Contours:  3\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2, 3]\n",
      "\n",
      "Image #:  31\n",
      "# of Contours:  1\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2, 3, 1]\n",
      "\n",
      "Image #:  32\n",
      "# of Contours:  3\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2, 3, 1, 3]\n",
      "\n",
      "Image #:  33\n",
      "# of Contours:  11\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2, 3, 1, 3, 11]\n",
      "\n",
      "Image #:  34\n",
      "# of Contours:  2\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2, 3, 1, 3, 11, 2]\n",
      "\n",
      "Image #:  35\n",
      "# of Contours:  1\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2, 3, 1, 3, 11, 2, 1]\n",
      "\n",
      "Image #:  36\n",
      "# of Contours:  5\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2, 3, 1, 3, 11, 2, 1, 5]\n",
      "\n",
      "Image #:  37\n",
      "# of Contours:  3\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2, 3, 1, 3, 11, 2, 1, 5, 3]\n",
      "\n",
      "Image #:  38\n",
      "# of Contours:  3\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2, 3, 1, 3, 11, 2, 1, 5, 3, 3]\n",
      "\n",
      "Image #:  39\n",
      "# of Contours:  3\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2, 3, 1, 3, 11, 2, 1, 5, 3, 3, 3]\n",
      "\n",
      "Image #:  40\n",
      "# of Contours:  2\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2, 3, 1, 3, 11, 2, 1, 5, 3, 3, 3, 2]\n",
      "\n",
      "Image #:  41\n",
      "# of Contours:  1\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2, 3, 1, 3, 11, 2, 1, 5, 3, 3, 3, 2, 1]\n",
      "\n",
      "Image #:  42\n",
      "# of Contours:  5\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2, 3, 1, 3, 11, 2, 1, 5, 3, 3, 3, 2, 1, 5]\n",
      "\n",
      "Image #:  43\n",
      "# of Contours:  3\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2, 3, 1, 3, 11, 2, 1, 5, 3, 3, 3, 2, 1, 5, 3]\n",
      "\n",
      "Image #:  44\n",
      "# of Contours:  3\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2, 3, 1, 3, 11, 2, 1, 5, 3, 3, 3, 2, 1, 5, 3, 3]\n",
      "\n",
      "Image #:  45\n",
      "# of Contours:  3\n",
      "# of Hierarchy:  1\n",
      "[1, 34, 49, 93, 64, 67, 54, 8, 1, 21, 1, 49, 93, 64, 67, 54, 8, 1, 21, 1, 1, 2, 4, 36, 49, 46, 28, 4, 2, 3, 1, 3, 11, 2, 1, 5, 3, 3, 3, 2, 1, 5, 3, 3, 3]\n",
      "\n",
      "\n",
      "Exceptions:  [0]\n",
      "Length:  1 \n",
      "\n",
      "(45, 128, 128, 3)\n",
      "(45,)\n",
      "\n",
      "Trying to save pickle to January/PICKLESNEW/Classify_Train_Texture_New_Prostate.pickle\n",
      "\n",
      "Pickle Saved Successfully!\n"
     ]
    }
   ],
   "source": [
    "if Mode == \"Train\":\n",
    "    resultDir = os.path.join(data_folder_R, \"Augment_January_23\", \"Result_Train/\")\n",
    "    resultDir_Labels = os.path.join(data_folder_R, \"Augment_January_23\", \"Result_Train_Labels/\")\n",
    "\n",
    "elif Mode == \"Test\":\n",
    "    resultDir = os.path.join(data_folder_R, \"Augment_January_23\", \"Result_Test/\")\n",
    "    resultDir_Labels = os.path.join(data_folder_R, \"Augment_January_23\", \"Result_Test_Labels/\")\n",
    "\n",
    "    \n",
    "if not os.path.exists(resultDir):\n",
    "    os.mkdir(resultDir)\n",
    "\n",
    "resultDir_O = os.path.join(resultDir,  str(Organ))\n",
    "\n",
    "if not os.path.exists(resultDir_O):\n",
    "    os.mkdir(resultDir_O)\n",
    "\n",
    "if not os.path.exists(resultDir_Labels):\n",
    "    os.mkdir(resultDir_Labels)\n",
    "\n",
    "resultExcelPath_Labels = os.path.join(resultDir_Labels,  str(Organ) + \".csv\")\n",
    "print(resultExcelPath_Labels)\n",
    "\n",
    "i_exception = []\n",
    "contours_ = []\n",
    "Save_No = 0\n",
    "    \n",
    "print(\"\\n\\t\\t\\t\\t===== Processing Image =====\")\n",
    "for i in range(len(folder_diff)):\n",
    "    \n",
    "    if Mode == \"Train\":\n",
    "        print(\"\\nImage #: \", str(Save_No))\n",
    "        \n",
    "        imagePath = os.path.join(path1, str(folder_diff[i]))\n",
    "        labelPath = os.path.join(path2, str(folder_label[i]))\n",
    "\n",
    "        gray_img = cv2.imread(imagePath, cv2.IMREAD_ANYDEPTH)  # original_img is the numpy.ndarray class\n",
    "        label_img = cv2.imread(labelPath, -1)  # If there is no -1, read as 0 as 8 bits, and read as the original image with -1\n",
    "\n",
    "        columns_list = ['Feature']\n",
    "\n",
    "        try:\n",
    "            resultExcelPath = os.path.join(resultDir_O, str(i) + \".csv\")\n",
    "            Save_No = Save_No + 1\n",
    "            \n",
    "            contours, hierarchy = cv2.findContours(label_img, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE) # Get the number and area of labels.\n",
    "            blank_image = np.zeros((label_img.shape[0], label_img.shape[1],3), np.uint8) # shape[1] is the width\n",
    "\n",
    "            for k in range(len(contours)):\n",
    "                copy_label_image = np.zeros((label_img.shape[0], label_img.shape[1]),np.uint8)  # To extract only that label\n",
    "\n",
    "                color = color_define_contour(Labels_[i])\n",
    "\n",
    "                cv2.polylines(blank_image, contours[k], True, color, 2)\n",
    "                cv2.fillPoly(copy_label_image, [contours[k]], (255)) # To extract only the corresponding mask\n",
    "\n",
    "                box = FindBoundingBox(contours[k] ) # Box extraction for gray image crop\n",
    "                cv2.rectangle( blank_image, (box[0], box[1]), ( box[0]+box[2], box[1]+box[3]), (255,0,255), 2 )\n",
    "\n",
    "                image_area_roi = gray_img[box[1]:box[1]+box[3], box[0]:box[0]+box[2]] # gray image crop\n",
    "                label_img_roi = copy_label_image[box[1]:box[1]+box[3], box[0]:box[0]+box[2]] # label image crop\n",
    "\n",
    "                # ndarray class is changed to 3D sitk format, RadioMics only receives 3D simpleITK object as input\n",
    "                image_area_roi_arr = np.expand_dims(image_area_roi, axis=0)\n",
    "                original_img_im3d = sitk.GetImageFromArray(image_area_roi_arr)\n",
    "                label_img_roi_arr = np.expand_dims(label_img_roi, axis=0)\n",
    "                label_img_im3d = sitk.GetImageFromArray(label_img_roi_arr)\n",
    "\n",
    "                extractor = featureextractor.RadiomicsFeatureExtractor()     # For 2D Shapes force2D=True\n",
    "                radiomics.setVerbosity(60)\n",
    "\n",
    "                try:\n",
    "                    results = extractor.execute(original_img_im3d, label_img_im3d, label=255)\n",
    "                except NameError:\n",
    "                    print(\"Mask is not defined\")\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                # Show output\n",
    "                featureDictionary={} # Initialize the dictionary to extract the result\n",
    "                features =[]\n",
    "                value_title = str(k)\n",
    "                values =[]\n",
    "                for featureName in results.keys():\n",
    "                    if featureName.find('diagnostics_') == -1 :\n",
    "                        new_feature_str = featureName[9:]\n",
    "                        features.append(new_feature_str )\n",
    "                        values.append(float(results[featureName]))\n",
    "\n",
    "                if k == 0 :\n",
    "                    computed_data = {'Feature': features, '0': values}\n",
    "                    df = pd.DataFrame(data=computed_data, columns=['Feature', '0'])\n",
    "                else:\n",
    "                    series_add = pd.Series( values, name = value_title )\n",
    "                    df = pd.concat([df, series_add], axis = 1)\n",
    "\n",
    "            print(\"# of Contours: \", len(contours))\n",
    "            print(\"# of Hierarchy: \", len(hierarchy))\n",
    "            contours_.append(df.shape[1]-1)\n",
    "            print(contours_)\n",
    "            df.to_csv(resultExcelPath, index = False, sep=',', line_terminator = '\\r')\n",
    "            \n",
    "        except:\n",
    "            i_exception.append(i)\n",
    "            pass\n",
    "\n",
    "\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"Exceptions: \",i_exception)\n",
    "print(\"Length: \",len(i_exception), \"\\n\")\n",
    "\n",
    "append_list_as_row(resultExcelPath_Labels, contours_)  \n",
    "\n",
    "Images_ = np.delete(Images_, i_exception, axis=0)\n",
    "Labels_ = np.delete(Labels_, i_exception)\n",
    "\n",
    "print(Images_.shape)\n",
    "print(Labels_.shape)\n",
    "save_pickle(Images_, Labels_, data_file)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
